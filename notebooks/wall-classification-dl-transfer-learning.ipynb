{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-13T17:14:52.899977Z","iopub.status.busy":"2023-09-13T17:14:52.899509Z","iopub.status.idle":"2023-09-13T17:15:41.750859Z","shell.execute_reply":"2023-09-13T17:15:41.749706Z","shell.execute_reply.started":"2023-09-13T17:14:52.899937Z"},"trusted":true},"outputs":[],"source":["# !pip install roboflow\n","\n","# from roboflow import Roboflow\n","# rf = Roboflow(api_key=\"D90rVo7ahGyBHqpqtBIH\")\n","# project = rf.workspace(\"indian-institute-of-information-technology-sricity\").project(\"wall-cracks\")\n","# dataset = project.version(2).download(\"tensorflow\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-13T17:16:07.744297Z","iopub.status.busy":"2023-09-13T17:16:07.742061Z","iopub.status.idle":"2023-09-13T17:16:08.186599Z","shell.execute_reply":"2023-09-13T17:16:08.185300Z","shell.execute_reply.started":"2023-09-13T17:16:07.744224Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import cv2\n","import joblib\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from sklearn.metrics import accuracy_score, precision_score\n","import tensorflow as tf\n","import matplotlib.image as mpimg\n","from sklearn.preprocessing import FunctionTransformer,LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","from keras.applications import ResNet50\n","from keras.models import Model\n","from keras.layers import Input, Flatten, Dense\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","from keras.applications import ResNet50\n","from keras.models import Model\n","from keras.layers import Input, Flatten, Dense\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Flatten, Dense\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-13T17:16:08.191557Z","iopub.status.busy":"2023-09-13T17:16:08.189740Z","iopub.status.idle":"2023-09-13T17:16:08.205895Z","shell.execute_reply":"2023-09-13T17:16:08.203840Z","shell.execute_reply.started":"2023-09-13T17:16:08.191503Z"},"trusted":true},"outputs":[],"source":["def load_data(dir , df):\n","    # Load images and labels into arrays\n","    images = []\n","    labels = []\n","\n","    for index, row in df.iterrows():\n","        image_file_path = os.path.join(dir, row['filename'])\n","        image = cv2.imread(image_file_path)\n","        if image is not None:\n","            resized_image = cv2.resize(image, (img_size, img_size))  # Resize to a fixed size\n","            resized_image = np.array(resized_image) / 255.0\n","        images.append(resized_image)\n","        labels.append(row['target'])\n","\n","    # Convert lists to numpy arrays\n","    return np.array(images) , np.array(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-13T17:16:08.209850Z","iopub.status.busy":"2023-09-13T17:16:08.208678Z","iopub.status.idle":"2023-09-13T17:16:08.217757Z","shell.execute_reply":"2023-09-13T17:16:08.216597Z","shell.execute_reply.started":"2023-09-13T17:16:08.209786Z"},"trusted":true},"outputs":[],"source":["img_size = 400"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-09-13T17:16:08.219406Z","iopub.status.busy":"2023-09-13T17:16:08.219119Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded data shape: (2125, 400, 400, 3)\n","Loaded labels shape: (2125,)\n"]}],"source":["dir = \"../dataset/Wall Cracks.v2i.tensorflow/train\"\n","df = pd.read_csv(dir + \"/_annotations.csv\")\n","label_encoder = LabelEncoder()\n","# Encode the 'class' column\n","df['target'] = label_encoder.fit_transform(df['class'])\n","\n","train_data, train_labels = load_data(dir , df)\n","\n","print(\"Loaded data shape:\", train_data.shape)\n","print(\"Loaded labels shape:\", train_labels.shape)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded data shape: (85, 400, 400, 3)\n","Loaded labels shape: (85,)\n"]}],"source":["dir = \"../dataset/Wall Cracks.v2i.tensorflow/test\"\n","df = pd.read_csv(dir + \"/_annotations.csv\")\n","label_encoder = LabelEncoder()\n","# Encode the 'class' column\n","df['target'] = label_encoder.fit_transform(df['class'])\n","\n","test_data, test_labels = load_data(dir , df)\n","\n","print(\"Loaded data shape:\", test_data.shape)\n","print(\"Loaded labels shape:\", test_labels.shape)"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded data shape: (85, 400, 400, 3)\n","Loaded labels shape: (85,)\n"]}],"source":["dir = \"../dataset/Wall Cracks.v2i.tensorflow/valid\"\n","df = pd.read_csv(dir + \"/_annotations.csv\")\n","label_encoder = LabelEncoder()\n","# Encode the 'class' column\n","df['target'] = label_encoder.fit_transform(df['class'])\n","\n","valid_data, valid_labels = load_data(dir , df)\n","\n","print(\"Loaded data shape:\", valid_data.shape)\n","print(\"Loaded labels shape:\", valid_labels.shape)"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["# Encode train_labels, valid_labels, and test_labels using one-hot encoding\n","train_labels_encoded = to_categorical(train_labels)\n","valid_labels_encoded = to_categorical(valid_labels)\n","test_labels_encoded = to_categorical(test_labels)"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training ResNet50V2...\n","Epoch 1/10\n","266/266 [==============================] - 1722s 6s/step - loss: 1.8172 - accuracy: 0.4329 - val_loss: 1.5905 - val_accuracy: 0.4471\n","Epoch 2/10\n","266/266 [==============================] - 1479s 6s/step - loss: 1.1898 - accuracy: 0.4287 - val_loss: 3.0223 - val_accuracy: 0.4471\n","Epoch 3/10\n","201/266 [=====================>........] - ETA: 6:01 - loss: 1.0350 - accuracy: 0.4347"]}],"source":["import pandas as pd\n","from keras.applications import VGG16, InceptionV3, MobileNet, DenseNet121, ResNet50V2\n","from keras.layers import Flatten, Dense\n","from keras.models import Model\n","from keras.optimizers import Adam\n","import numpy as np\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import os\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Function to create and compile the CNN model\n","def create_and_compile_model_CNN(img_size, num_classes, base_model):\n","    base_model = base_model(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n","    \n","    x = base_model.output\n","    x = Flatten()(x)\n","    x = Dense(512, activation='relu')(x)\n","    output = Dense(num_classes, activation='softmax')(x)\n","    \n","    model = Model(inputs=base_model.input, outputs=output)\n","    \n","    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Create a directory to save models\n","if not os.path.exists('./models'):\n","    os.makedirs('./models')\n","\n","models = {\n","#     \"VGG16\": VGG16,\n","#     \"InceptionV3\": InceptionV3,\n","#     \"MobileNet\": MobileNet,\n","#     \"DenseNet121\": DenseNet121,\n","    \"ResNet50V2\": ResNet50V2\n","}\n","\n","num_classes = 3\n","batch_size = 8\n","epochs = 10\n","img_size = 400\n","results = []\n","\n","# Data loading and preprocessing should be done here (train_data, train_labels_encoded, valid_data, valid_labels_encoded, test_data, test_labels).\n","\n","for model_name, base_model in models.items():\n","    print(f\"Training {model_name}...\")\n","    model = create_and_compile_model_CNN(img_size, num_classes, base_model)\n","    model.fit(train_data, train_labels_encoded, batch_size=batch_size, epochs=epochs, validation_data=(valid_data, valid_labels_encoded))\n","    \n","    # Save the model\n","    model.save(f'./models/{model_name}_model.h5')\n","    \n","    predictions = model.predict(test_data)\n","    predicted_labels = np.argmax(predictions, axis=1)\n","    \n","    accuracy = accuracy_score(test_labels, predicted_labels)\n","    print(f\"{model_name} Accuracy: {accuracy:.2f}\")\n","    \n","    # Generate and save confusion matrix\n","    cm = confusion_matrix(test_labels, predicted_labels)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n","    plt.xlabel('Predicted Labels')\n","    plt.ylabel('True Labels')\n","    plt.title(f'Confusion Matrix for {model_name}')\n","    plt.savefig(f'./models/{model_name}_confusion_matrix.png')\n","    \n","    results.append({\n","        \"Model\": model_name,\n","        \"Accuracy\": accuracy,\n","        \"Predicted Labels\": predicted_labels.tolist()\n","    })\n","\n","df = pd.DataFrame(results)\n","# print(df)\n","df.to_csv(\"model_results.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
