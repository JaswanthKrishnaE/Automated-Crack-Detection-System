{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install roboflow\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"D90rVo7ahGyBHqpqtBIH\")\nproject = rf.workspace(\"indian-institute-of-information-technology-sricity\").project(\"wall-crack-detection-own\")\ndataset = project.version(3).download(\"folder\")","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:52:02.413202Z","iopub.execute_input":"2023-09-29T15:52:02.413596Z","iopub.status.idle":"2023-09-29T15:52:14.247328Z","shell.execute_reply.started":"2023-09-29T15:52:02.413568Z","shell.execute_reply":"2023-09-29T15:52:14.246261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ndef walkthrough_dir(dir_path):\n  for dpath, dname, filename in os.walk(dir_path):\n    print(f'There are {len(dname)} directories and {len(filename)} files in {dpath}.')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:52:14.249783Z","iopub.execute_input":"2023-09-29T15:52:14.250754Z","iopub.status.idle":"2023-09-29T15:52:14.255867Z","shell.execute_reply.started":"2023-09-29T15:52:14.250717Z","shell.execute_reply":"2023-09-29T15:52:14.255005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/working/wall-crack-detection-own-3/train'\nvalid_dir = '/kaggle/working/wall-crack-detection-own-3/valid'\ntest_dir = '/kaggle/working/wall-crack-detection-own-3/test'","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:52:14.257483Z","iopub.execute_input":"2023-09-29T15:52:14.257816Z","iopub.status.idle":"2023-09-29T15:52:14.268077Z","shell.execute_reply.started":"2023-09-29T15:52:14.257782Z","shell.execute_reply":"2023-09-29T15:52:14.267265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"walkthrough_dir('/kaggle/working/wall-crack-detection-own-3')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:52:14.270326Z","iopub.execute_input":"2023-09-29T15:52:14.270856Z","iopub.status.idle":"2023-09-29T15:52:14.280236Z","shell.execute_reply.started":"2023-09-29T15:52:14.270827Z","shell.execute_reply":"2023-09-29T15:52:14.279280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Getting Data Ready**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nIMG_SIZE = (640,640)\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n                                                                 label_mode='categorical',\n                                                                 image_size=IMG_SIZE)\nvalid_data = tf.keras.preprocessing.image_dataset_from_directory(valid_dir,\n                                                                 label_mode='categorical',\n                                                                 image_size=IMG_SIZE,\n                                                                 shuffle=False)\ntest_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n                                                                label_mode='categorical',\n                                                                image_size=IMG_SIZE,\n                                                                shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:52:14.281626Z","iopub.execute_input":"2023-09-29T15:52:14.282652Z","iopub.status.idle":"2023-09-29T15:52:14.383445Z","shell.execute_reply.started":"2023-09-29T15:52:14.282622Z","shell.execute_reply":"2023-09-29T15:52:14.382647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Checkpoint**\n---\nA **checkpoint** is an intermediate dump of a model's entire internal state (its weights, current learning rate, etc.) so that the framework can resume the training from this point whenever desired.","metadata":{}},{"cell_type":"code","source":"checkpoint_path = 'fruits_classification_model_checkpoint'\ncheckpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n                                                         save_weights_only=True,\n                                                         monitor='val_accuracy',\n                                                         save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:52:14.384801Z","iopub.execute_input":"2023-09-29T15:52:14.385327Z","iopub.status.idle":"2023-09-29T15:52:14.390189Z","shell.execute_reply.started":"2023-09-29T15:52:14.385297Z","shell.execute_reply":"2023-09-29T15:52:14.389262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Augmentation**\n---\n**Data augmentation** is the process of transforming images to create new ones, for training machine learning models.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.models import Sequential\n\ndata_augmentation = Sequential([\n    preprocessing.RandomFlip('horizontal'),\n    preprocessing.RandomRotation(0.2),\n    preprocessing.RandomHeight(0.2),\n    preprocessing.RandomWidth(0.2),\n    preprocessing.RandomZoom(0.2),\n    preprocessing.Rescaling(1/255.)\n],name='data_augmenation')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:52:14.391607Z","iopub.execute_input":"2023-09-29T15:52:14.392153Z","iopub.status.idle":"2023-09-29T15:52:14.418860Z","shell.execute_reply.started":"2023-09-29T15:52:14.392124Z","shell.execute_reply":"2023-09-29T15:52:14.417987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Building**\n---\nWe will be using the Keras **Functional API** which is a way to create models that are more flexible than the **tf.keras.Sequential API**. The functional API can handle models with non-linear topology, shared layers, and even multiple inputs or outputs.\n\nThe main idea is that a deep learning model is usually a **directed acyclic graph (DAG)** of layers. So the functional API is a way to build graphs of layers.\n\nWe will be using 2 pretrained models here. So basically this will be **Transfer Learning**.The reuse of a pre-trained model on a new problem is known as transfer learning in machine learning. A machine uses the knowledge learned from a prior assignment to increase prediction about a new task in transfer learning.\n1. EfficientNetB0\n2. MobileNetV2","metadata":{}},{"cell_type":"markdown","source":"**MobileNetV2**","metadata":{}},{"cell_type":"code","source":"base_model_1 = tf.keras.applications.MobileNetV2(include_top=False)\nbase_model_1.trainable = False\n\ninputs = layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3), name=\"input_layer\")\nx = data_augmentation(inputs)\nx = base_model_1(x, training=False)\nx = layers.GlobalAveragePooling2D(name=\"global_average_pooling\")(x)\noutputs = layers.Dense(len(train_data.class_names), activation=\"softmax\", name=\"output_layer\")(x)\nmobilenet_model = tf.keras.Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:52:14.420232Z","iopub.execute_input":"2023-09-29T15:52:14.420554Z","iopub.status.idle":"2023-09-29T15:52:16.225264Z","shell.execute_reply.started":"2023-09-29T15:52:14.420522Z","shell.execute_reply":"2023-09-29T15:52:16.224310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobilenet_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:52:16.226456Z","iopub.execute_input":"2023-09-29T15:52:16.226776Z","iopub.status.idle":"2023-09-29T15:52:16.260214Z","shell.execute_reply.started":"2023-09-29T15:52:16.226743Z","shell.execute_reply":"2023-09-29T15:52:16.259351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobilenet_model.compile(loss='categorical_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=['accuracy'])\nmobilenet_model_hist = mobilenet_model.fit(train_data,\n                 epochs=10,\n                 validation_data=valid_data,\n                 #validation_steps=int(0.15 * len(valid_data)),\n                 callbacks=[checkpoint_callback])","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:52:16.263136Z","iopub.execute_input":"2023-09-29T15:52:16.263633Z","iopub.status.idle":"2023-09-29T15:55:13.878927Z","shell.execute_reply.started":"2023-09-29T15:52:16.263603Z","shell.execute_reply":"2023-09-29T15:55:13.878004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobilenet_model_loss, mobilenet_model_acc = mobilenet_model.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:55:13.880628Z","iopub.execute_input":"2023-09-29T15:55:13.880977Z","iopub.status.idle":"2023-09-29T15:55:14.593716Z","shell.execute_reply.started":"2023-09-29T15:55:13.880922Z","shell.execute_reply":"2023-09-29T15:55:14.592827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Specify the file path where you want to save your model\nmodel_save_path = '/kaggle/working/models/mobilenet_model.h5'\n\n# Save the model to the specified file\nmobilenet_model.save(model_save_path)\n\nprint(f\"Model saved to {model_save_path}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-29T16:08:50.460362Z","iopub.execute_input":"2023-09-29T16:08:50.460730Z","iopub.status.idle":"2023-09-29T16:08:50.759165Z","shell.execute_reply.started":"2023-09-29T16:08:50.460704Z","shell.execute_reply":"2023-09-29T16:08:50.758185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"Training Loss    : {:.4} | Baseline : {:.4}\".format(mobilenet_model_loss, efficient_model_loss))\n# print(\"Training Accuracy: {:.4}% | Baseline : {:.4}%\".format(mobilenet_model_acc*100, efficient_model_acc*100))","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:55:14.868787Z","iopub.execute_input":"2023-09-29T15:55:14.869473Z","iopub.status.idle":"2023-09-29T15:55:14.873770Z","shell.execute_reply.started":"2023-09-29T15:55:14.869421Z","shell.execute_reply":"2023-09-29T15:55:14.872873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Assuming you have already trained your model and saved the training history in mobilenet_model_hist.\n\n# Plot training & validation loss values\nplt.plot(mobilenet_model_hist.history['loss'])\nplt.plot(mobilenet_model_hist.history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Validation'], loc='upper right')\nplt.show()\n\n# Plot training & validation accuracy values\nplt.plot(mobilenet_model_hist.history['accuracy'])\nplt.plot(mobilenet_model_hist.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Validation'], loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:55:14.874999Z","iopub.execute_input":"2023-09-29T15:55:14.875568Z","iopub.status.idle":"2023-09-29T15:55:15.499999Z","shell.execute_reply.started":"2023-09-29T15:55:14.875535Z","shell.execute_reply":"2023-09-29T15:55:15.499014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\ndef save_confusion_matrix(model, data, title, filename):\n    predictions = model.predict(data)\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Assuming data is a tf.data.Dataset, extract labels\n    labels = np.concatenate([y for x, y in data], axis=0)\n    true_labels = np.argmax(labels, axis=1)\n    \n    accuracy = accuracy_score(true_labels, predicted_labels)\n    cm = confusion_matrix(true_labels, predicted_labels)\n    \n    num_classes = len(cm)\n    \n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(num_classes), yticklabels=range(num_classes))\n    plt.xlabel('Predicted Labels')\n    plt.ylabel('True Labels')\n    plt.title(f'{title} (Accuracy: {accuracy:.2f})')\n    plt.savefig(filename)\n    plt.show()\n\n# Save confusion matrices for train, validation, and test data\n# save_confusion_matrix(mobilenet_model, train_data, \"Train Data Confusion Matrix\", \"train_confusion_matrix.png\")\nsave_confusion_matrix(mobilenet_model, valid_data, \"Validation Data Confusion Matrix\", \"valid_confusion_matrix.png\")\nsave_confusion_matrix(mobilenet_model, test_data, \"Test Data Confusion Matrix\", \"test_confusion_matrix.png\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T16:03:46.505851Z","iopub.execute_input":"2023-09-29T16:03:46.506232Z","iopub.status.idle":"2023-09-29T16:03:49.678895Z","shell.execute_reply.started":"2023-09-29T16:03:46.506203Z","shell.execute_reply":"2023-09-29T16:03:49.677923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}